{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed4973a6-eb42-4676-8f9a-1789b6b5cc98",
   "metadata": {},
   "source": [
    "Using Python with Ollama : We can use multiple features of Ollama to generate variety of response here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e176821e-6e2f-4e0d-8663-b984d7dce2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "First we need to import the Ollama from Ollama library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6f312ee-8ae7-4ec5-92ad-74145e7daf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f201a986-8a62-4d5c-9f9d-e73eb2da8acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "At first we generate LLM response using the keyword \"ollama.generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3c87e2d-22a7-454b-a0b1-f9ae12d9fa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ollama.generate(model='llama3.2', \n",
    "prompt='Give me a joke on Generative AI',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc6d46fb-70d8-4551-83fa-ff52ad97097b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the Generative AI go to therapy?\n",
      "\n",
      "Because it was struggling to generate meaningful relationships and kept rewriting its past.\n"
     ]
    }
   ],
   "source": [
    "print(result['response']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1798c1-f8bd-4949-ae91-48ad437f40d8",
   "metadata": {},
   "source": [
    "Here we get LLM response using keyword \"ollama.chat\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c95e52ab-ece9-4277-9926-083a20992e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "Why did the married couple bring a ladder to therapy?\n",
      "\n",
      "Because they wanted to take their relationship to the next level! (get it?)\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(model='llama3.2', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'Give me joke on married couples',\n",
    "    },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45cbb5f2-bb0a-44e2-b1e6-b8b0b2daa655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama3.2',\n",
       " 'created_at': '2024-10-22T08:28:16.2273924Z',\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': \"Here's one:\\n\\nWhy did the married couple bring a ladder to therapy?\\n\\nBecause they wanted to take their relationship to the next level! (get it?)\"},\n",
       " 'done_reason': 'stop',\n",
       " 'done': True,\n",
       " 'total_duration': 9780485400,\n",
       " 'load_duration': 111230500,\n",
       " 'prompt_eval_count': 31,\n",
       " 'prompt_eval_duration': 3329855000,\n",
       " 'eval_count': 32,\n",
       " 'eval_duration': 6321328000}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fc486b-1479-4e2b-b5d4-482eeb8fe194",
   "metadata": {},
   "source": [
    "We can evaluate the each response receive by the model as done above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7147b95-abe8-40a5-a333-2f69414d4f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "Python Rest API test code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3d4c0a-0f79-4dfb-b209-7239ef21b5af",
   "metadata": {},
   "source": [
    "Now next we will move to \"Ollama Python Rest API\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d6196e3-22f5-4901-aa11-a0ec55919b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh boy, are you ready for an adventure?\n",
      "\n",
      "So, you know how things have weight, right? Like your toys and your favorite book. And you can't just lift them up into the air and make them float away. That's because of something called gravity.\n",
      "\n",
      "Gravity is like a magic string that pulls everything towards each other! It's what keeps you on the ground and what makes things fall down when you drop them.\n",
      "\n",
      "Imagine you have a ball, and you throw it up in the air. What happens? It comes back down to the ground, right? That's because the Earth is pulling on the ball with its gravity. The Earth wants to keep the ball close, so it pulls it back down.\n",
      "\n",
      "But here's the really cool thing about gravity: everything has gravity! Even you do! That means that if you were standing on a big trampoline, you would be pulling the trampoline towards yourself with your gravity. And if someone else was on the other side of the trampoline, they would be pulling them towards themselves too!\n",
      "\n",
      "So, gravity is like a big hug from the Earth and everything in it. It's what keeps us safe on the ground and what makes things fall down.\n",
      "\n",
      "Does that make sense?\n"
     ]
    }
   ],
   "source": [
    "from ollama import Client\n",
    "client = Client(host='http://localhost:11434')\n",
    "response = client.chat(model='llama3.2', messages=[\n",
    "                       {\n",
    "                            'role': 'user',\n",
    "                            'content': 'explain gravity to a six year old',\n",
    "    },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f643f9a2-7515-4ec7-a9d5-57f086de8db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama3.2',\n",
       " 'created_at': '2024-10-22T08:34:55.5789435Z',\n",
       " 'message': {'role': 'assistant',\n",
       "  'content': \"Oh boy, are you ready for an adventure?\\n\\nSo, you know how things have weight, right? Like your toys and your favorite book. And you can't just lift them up into the air and make them float away. That's because of something called gravity.\\n\\nGravity is like a magic string that pulls everything towards each other! It's what keeps you on the ground and what makes things fall down when you drop them.\\n\\nImagine you have a ball, and you throw it up in the air. What happens? It comes back down to the ground, right? That's because the Earth is pulling on the ball with its gravity. The Earth wants to keep the ball close, so it pulls it back down.\\n\\nBut here's the really cool thing about gravity: everything has gravity! Even you do! That means that if you were standing on a big trampoline, you would be pulling the trampoline towards yourself with your gravity. And if someone else was on the other side of the trampoline, they would be pulling them towards themselves too!\\n\\nSo, gravity is like a big hug from the Earth and everything in it. It's what keeps us safe on the ground and what makes things fall down.\\n\\nDoes that make sense?\"},\n",
       " 'done_reason': 'stop',\n",
       " 'done': True,\n",
       " 'total_duration': 90140307400,\n",
       " 'load_duration': 23314375700,\n",
       " 'prompt_eval_count': 32,\n",
       " 'prompt_eval_duration': 12108615000,\n",
       " 'eval_count': 249,\n",
       " 'eval_duration': 54618607000}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0350b36b-9367-403b-b917-23047d8b94df",
   "metadata": {},
   "source": [
    "Using ApenAI and Ollama Integration to get more refined replys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7324fbf1-b47c-4931-aeff-76163a25cc76",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      3\u001b[0m llm \u001b[38;5;241m=\u001b[39m OpenAI(\n\u001b[0;32m      4\u001b[0m     base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//localhost:11414/v1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m     api_kays \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblank\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# required for external clients.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m response \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      9\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllama3.2\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     }],\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    base_url = 'http\"//localhost:11414/v1',\n",
    "    api_kays = 'blank', # required for external clients.\n",
    ")\n",
    "\n",
    "response = llm.chat.completions.create(\n",
    "    model='llama3.2',\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Say this is a test\",\n",
    "    }],\n",
    ")\n",
    "\n",
    "print(response.choices(0).message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5328e1c-f23e-43de-8e0a-ae0be189bdb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
